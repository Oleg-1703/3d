#!/usr/bin/env python3
"""
–ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –°–ï–ì–ú–ï–ù–¢–ê–¶–ò–ò
–ò—Å–ø—Ä–∞–≤–ª—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞, –°–û–•–†–ê–ù–Ø–Ø –º–∞—Å–∫–∏ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏!
"""

import os

def fix_segmentation_train():
    with open('train.py', 'r') as f:
        content = f.read()
    
    # –ë—ç–∫–∞–ø
    with open('train.py.segmentation_backup', 'w') as f:
        f.write(content)
    
    print("‚úÖ –°–æ–∑–¥–∞–Ω –±—ç–∫–∞–ø train.py.segmentation_backup")
    
    # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï 1: –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –¥–ª—è Gaussian Grouping
    # –ó–∞–º–µ–Ω—è–µ–º –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
    old_classifier_section = '''classifier = SegmentationNetwork(feature_size=3, num_classes=dataset.num_classes).to(device)
    classifier_optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001)'''
    
    new_classifier_section = '''# –ü–†–ê–í–ò–õ–¨–ù–´–ô –ö–õ–ê–°–°–ò–§–ò–ö–ê–¢–û–† –¥–ª—è Gaussian Grouping —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
    classifier = torch.nn.Conv2d(1, dataset.num_classes, kernel_size=1).to(device)
    cls_criterion = torch.nn.CrossEntropyLoss(reduction='none')
    cls_optimizer = torch.optim.Adam(classifier.parameters(), lr=5e-4)
    print(f"–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å–æ–∑–¥–∞–Ω: 1 -> {dataset.num_classes} –∫–ª–∞—Å—Å–æ–≤")'''
    
    if 'SegmentationNetwork' in content:
        content = content.replace(old_classifier_section, new_classifier_section)
        print("‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä")
    
    # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï 2: –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ render_object
    # –ò—â–µ–º –±–ª–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∏ –∑–∞–º–µ–Ω—è–µ–º –µ–≥–æ –Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—É—é –≤–µ—Ä—Å–∏—é
    segmentation_block_start = content.find('# –ü–æ—Ç–µ—Ä—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏')
    if segmentation_block_start == -1:
        segmentation_block_start = content.find('loss_obj_3d = torch.tensor(0.0, device=device')
    
    if segmentation_block_start != -1:
        # –ù–∞—Ö–æ–¥–∏–º –∫–æ–Ω–µ—Ü –±–ª–æ–∫–∞
        segmentation_block_end = content.find('# –û–±—â–∞—è –ø–æ—Ç–µ—Ä—è', segmentation_block_start)
        if segmentation_block_end == -1:
            segmentation_block_end = content.find('loss = Ll1', segmentation_block_start)
        
        if segmentation_block_end != -1:
            # –ó–∞–º–µ–Ω—è–µ–º –í–ï–°–¨ –±–ª–æ–∫ –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω—É—é Gaussian Grouping —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é
            new_segmentation_code = '''# –ü–†–ê–í–ò–õ–¨–ù–ê–Ø –°–ï–ì–ú–ï–ù–¢–ê–¶–ò–Ø GAUSSIAN GROUPING
        
        # Object Loss - –∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º train.py
        if hasattr(viewpoint_cam, 'objects') and viewpoint_cam.objects is not None:
            try:
                # –ü–æ–ª—É—á–∞–µ–º gt –º–∞—Å–∫–∏ –æ–±—ä–µ–∫—Ç–æ–≤  
                gt_obj = viewpoint_cam.objects.to(device).long()
                
                # objects –∏–∑ —Ä–µ–Ω–¥–µ—Ä–∞ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å [C, H, W] –≥–¥–µ C - –∫–∞–Ω–∞–ª—ã –æ–±—ä–µ–∫—Ç–æ–≤
                if "render_object" in render_pkg:
                    objects = render_pkg["render_object"]  # [C, H, W]
                    
                    print(f'objects shape: {objects.shape}, gt_obj shape: {gt_obj.shape}')
                    
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º objects –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
                    # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –æ–∂–∏–¥–∞–µ—Ç [batch, 1, H, W]
                    if objects.dim() == 3:  # [C, H, W]
                        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –∫–∞–Ω–∞–ª –∫–∞–∫ –æ–±—ä–µ–∫—Ç–Ω—É—é –∫–∞—Ä—Ç—É
                        objects_input = objects[0:1].unsqueeze(0)  # [1, 1, H, W]
                    elif objects.dim() == 2:  # [H, W] 
                        objects_input = objects.unsqueeze(0).unsqueeze(0)  # [1, 1, H, W]
                    else:
                        objects_input = objects.float()
                    
                    # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ —Ä–∞–∑–º–µ—Ä—ã —Å–æ–≤–ø–∞–¥–∞—é—Ç
                    if objects_input.shape[-2:] != gt_obj.shape[-2:]:
                        # –†–µ—Å–∞–π–∑–∏–º gt_obj –∫ —Ä–∞–∑–º–µ—Ä—É objects
                        gt_obj = torch.nn.functional.interpolate(
                            gt_obj.float().unsqueeze(0).unsqueeze(0),
                            size=objects_input.shape[-2:],
                            mode='nearest'
                        ).squeeze().long()
                    
                    # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤
                    logits = classifier(objects_input.float())  # [1, num_classes, H, W]
                    
                    print(f'logits shape: {logits.shape}, gt_obj shape: {gt_obj.shape}')
                    
                    # –ü—Ä–∏–≤–æ–¥–∏–º gt_obj –∫ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É –¥–ª—è loss
                    if gt_obj.dim() == 2:  # [H, W]
                        target = gt_obj.unsqueeze(0)  # [1, H, W] 
                    else:
                        target = gt_obj
                    
                    # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ —Ä–∞–∑–º–µ—Ä—ã –ª–æ–≥–∏—Ç–æ–≤ –∏ —Ç–∞—Ä–≥–µ—Ç–∞ —Å–æ–≤–ø–∞–¥–∞—é—Ç
                    if logits.shape[-2:] != target.shape[-2:]:
                        target = torch.nn.functional.interpolate(
                            target.float().unsqueeze(0),
                            size=logits.shape[-2:],
                            mode='nearest'
                        ).squeeze().long()
                        if target.dim() == 2:
                            target = target.unsqueeze(0)
                    
                    # –í—ã—á–∏—Å–ª—è–µ–º object loss
                    loss_obj = cls_criterion(logits, target).mean()
                    loss_obj = loss_obj / torch.log(torch.tensor(dataset.num_classes, device=device))  # –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
                    
                    print(f'Object loss: {loss_obj.item():.4f}')
                    
                else:
                    print("–ù–µ—Ç render_object –≤ render_pkg")
                    loss_obj = torch.tensor(0.0, device=device, requires_grad=True)
                    
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –≤ object segmentation –Ω–∞ –∏—Ç–µ—Ä–∞—Ü–∏–∏ {iteration}: {e}")
                loss_obj = torch.tensor(0.0, device=device, requires_grad=True)
        else:
            print("–ù–µ—Ç –æ–±—ä–µ–∫—Ç–Ω—ã—Ö –º–∞—Å–æ–∫ –¥–ª—è –∫–∞–º–µ—Ä—ã")
            loss_obj = torch.tensor(0.0, device=device, requires_grad=True)
        
        # 3D Regularization loss (–∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ)
        loss_obj_3d = None
        if iteration % opt.reg3d_interval == 0 and hasattr(gaussians, '_objects_dc') and gaussians._objects_dc.numel() > 0:
            try:
                # 3D –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è Gaussians  
                logits3d = classifier(gaussians._objects_dc.permute(2,0,1))  # [num_classes, num_points, 1]
                prob_obj3d = torch.softmax(logits3d, dim=0).squeeze().permute(1,0)  # [num_points, num_classes]
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º 3D loss –∏–∑ utils
                loss_obj_3d = loss_cls_3d(
                    gaussians._xyz.squeeze().detach(), 
                    prob_obj3d, 
                    opt.reg3d_k, 
                    opt.reg3d_lambda_val, 
                    opt.reg3d_max_points, 
                    opt.reg3d_sample_size
                )
                print(f'3D regularization loss: {loss_obj_3d.item():.4f}')
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –≤ 3D regularization: {e}")
                loss_obj_3d = torch.tensor(0.0, device=device, requires_grad=True)

        '''
            
            content = content[:segmentation_block_start] + new_segmentation_code + content[segmentation_block_end:]
            print("‚úÖ –ó–∞–º–µ–Ω–µ–Ω –±–ª–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω—É—é Gaussian Grouping –≤–µ—Ä—Å–∏—é")
    
    # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï 3: –ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –æ–±—â–µ–π –ø–æ—Ç–µ—Ä–∏ (–∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ)
    old_loss_computation = 'loss = Ll1 + 0.1 * loss_obj_3d'
    
    new_loss_computation = '''# –û–±—â–∞—è –ø–æ—Ç–µ—Ä—è (Gaussian Grouping —Å—Ç–∏–ª—å)
        if loss_obj_3d is not None:
            # –ü–æ–ª–Ω–∞—è –ø–æ—Ç–µ—Ä—è —Å SSIM, object loss –∏ 3D regularization
            loss = ((1.0 - opt.lambda_dssim) * Ll1 + 
                   opt.lambda_dssim * (1.0 - ssim(image, gt_image)) + 
                   loss_obj + loss_obj_3d)
            print(f'Full loss: L1={Ll1.item():.4f}, Obj={loss_obj.item():.4f}, 3D={loss_obj_3d.item():.4f}')
        else:
            # –ü–æ—Ç–µ—Ä—è –±–µ–∑ 3D regularization
            loss = ((1.0 - opt.lambda_dssim) * Ll1 + 
                   opt.lambda_dssim * (1.0 - ssim(image, gt_image)) + 
                   loss_obj)
            print(f'Loss: L1={Ll1.item():.4f}, Obj={loss_obj.item():.4f}')'''
    
    # –ó–∞–º–µ–Ω—è–µ–º –ø—Ä–æ—Å—Ç–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –ø–æ—Ç–µ—Ä–∏ –Ω–∞ –ø–æ–ª–Ω–æ–µ
    if old_loss_computation in content:
        content = content.replace(old_loss_computation, new_loss_computation)
        print("‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –ø–æ—Ç–µ—Ä–∏")
    
    # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï 4: –î–æ–±–∞–≤–ª—è–µ–º optimizer step –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
    optimizer_step_location = content.find('gaussians.optimizer.step()')
    if optimizer_step_location != -1:
        # –î–æ–±–∞–≤–ª—è–µ–º step –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ –ø–æ—Å–ª–µ step gaussians
        new_optimizer_code = '''gaussians.optimizer.step()
                gaussians.optimizer.zero_grad(set_to_none=True)
                
                # –®–∞–≥ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
                cls_optimizer.step()
                cls_optimizer.zero_grad(set_to_none=True)'''
        
        end_line = content.find('\n', optimizer_step_location)
        content = content[:optimizer_step_location] + new_optimizer_code + content[end_line+1:]
        print("‚úÖ –î–æ–±–∞–≤–ª–µ–Ω optimizer step –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
    with open('train.py', 'w') as f:
        f.write(content)
    
    print("‚úÖ –°–ï–ì–ú–ï–ù–¢–ê–¶–ò–Ø –ü–û–õ–ù–û–°–¢–¨–Æ –ò–°–ü–†–ê–í–õ–ï–ù–ê!")
    print("üéØ –ú–∞—Å–∫–∏ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –∏ –±—É–¥—É—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ!")

if __name__ == "__main__":
    print("üö® –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –°–ï–ì–ú–ï–ù–¢–ê–¶–ò–ò GAUSSIAN GROUPING")
    print("–ò—Å–ø—Ä–∞–≤–ª—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞, –°–û–•–†–ê–ù–Ø–Ø –º–∞—Å–∫–∏!")
    fix_segmentation_train()
    print("\nüéØ –ì–æ—Ç–æ–≤–æ! –¢–µ–ø–µ—Ä—å –∑–∞–ø—É—Å–∫–∞–π—Ç–µ —Å –ø–æ–ª–Ω–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–µ–π:")
    print("python3 train.py -s data/dataset -r 1 -m output/dataset --config_file config/gaussian_dataset/train.json")